{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pandas\n!pip install numpy\nimport pandas as pd\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.models import Model\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\n\n# Set the path to the dataset files\ndataset_path = '/kaggle/input/fashion-product-images-dataset/fashion-dataset'\n\n# Load the style.csv file\ndf = pd.read_csv(dataset_path + '/styles.csv', usecols=['id', 'baseColour', 'articleType', 'season', 'gender'], on_bad_lines='skip')\n\n# Filter out rows with missing values\ndf = df.dropna()\n\n# Convert 'id' column to string data type and modify to include the image file extension\ndf['id'] = df['id'].astype(str) + '.jpg'\n\n# Encode categorical labels\nlabel_encoder = LabelEncoder()\ndf['baseColour'] = label_encoder.fit_transform(df['baseColour'])\ndf['articleType'] = label_encoder.fit_transform(df['articleType'])\ndf['season'] = label_encoder.fit_transform(df['season'])\ndf['gender'] = label_encoder.fit_transform(df['gender'])\n\n# Split the dataset into training and testing sets\ntrain_ratio = 0.8\ntrain_size = int(len(df) * train_ratio)\ntrain_df = df[:train_size]\ntest_df = df[train_size:]\n\n# Preprocess the image data\nimage_size = (224, 224)  # Adjust the size as needed\n\n# Define an image data generator\ndatagen = ImageDataGenerator(rescale=1./255)\n\n# Prepare the training data\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=dataset_path + '/images',\n    x_col='id',\n    y_col=['baseColour', 'articleType', 'season', 'gender'],\n    target_size=image_size,\n    batch_size=32,\n    class_mode='raw')\n\n# Prepare the testing data\ntest_generator = datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory=dataset_path + '/images',\n    x_col='id',\n    y_col=['baseColour', 'articleType', 'season', 'gender'],\n    target_size=image_size,\n    batch_size=32,\n    class_mode='raw')\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-28T07:39:03.930841Z","iopub.execute_input":"2023-05-28T07:39:03.931270Z","iopub.status.idle":"2023-05-28T07:40:55.057587Z","shell.execute_reply.started":"2023-05-28T07:39:03.931237Z","shell.execute_reply":"2023-05-28T07:40:55.056168Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.23.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mFound 35525 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:1137: UserWarning: Found 3 invalid image filename(s) in x_col=\"id\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 8880 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:1137: UserWarning: Found 2 invalid image filename(s) in x_col=\"id\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"for column in ['baseColour', 'articleType', 'season', 'gender']:\n    unique_values = train_df[column].unique()\n    num_unique_values = len(unique_values)\n    num_classes = len(train_df[column].unique())\n    print(f\"{column}: Number of unique values: {num_unique_values}, Number of classes: {num_classes}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-28T07:41:03.770690Z","iopub.execute_input":"2023-05-28T07:41:03.771115Z","iopub.status.idle":"2023-05-28T07:41:03.782748Z","shell.execute_reply.started":"2023-05-28T07:41:03.771081Z","shell.execute_reply":"2023-05-28T07:41:03.781530Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"baseColour: Number of unique values: 46, Number of classes: 46\narticleType: Number of unique values: 140, Number of classes: 140\nseason: Number of unique values: 4, Number of classes: 4\ngender: Number of unique values: 5, Number of classes: 5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the number of classes for each label\nnum_classes = [train_df[column].nunique() for column in ['baseColour', 'articleType', 'season', 'gender']]\n\n\n\n# Print the unique values and number of classes for each label\nfor i, column in enumerate(['baseColour', 'articleType', 'season', 'gender']):\n    unique_values = train_df[column].unique()\n    print(f\"{column}: Unique values: {unique_values}\")\n    print(f\"{column}: Number of classes: {num_classes[i]}\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-28T07:41:07.503481Z","iopub.execute_input":"2023-05-28T07:41:07.503899Z","iopub.status.idle":"2023-05-28T07:41:07.516000Z","shell.execute_reply.started":"2023-05-28T07:41:07.503866Z","shell.execute_reply":"2023-05-28T07:41:07.515112Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"baseColour: Unique values: [25  2 37  1 13 12 32 44  0  4  3 42  8 31 27 19 33 15 29  7 45  6 11 39\n 40 22 18 16 36  9 30 28 38  5 14 35 34 17 20 43 21 24 41 26 23 10]\nbaseColour: Number of classes: 46\narticleType: Unique values: [104  56 140 128 134 110  19   7  39  48 127  13 100 105 120  27  41  14\n  72  38  63 138 112 107  15 101  91  51 116  53  90  84  65 102  92  28\n  87 109 139   8  94  62  22 108   2  18 132  31  16  12  58  30  17  69\n   5  82 135  55 133  73  37  85  29 111  42 119  44 131 129 121 106  43\n   3  88 123   1  66  52 130  64  81  80  68  34  23  32   0   6  59  60\n 141 118  70  95  99  89 113  33  50 125  83  20  75  35  74  45  78 142\n 122 124  40 114 103  86  98  25  57  47  24  96   9 117  11 137  46  97\n   4  67  21  77 126  26  61  76  71 136  36  49  79  93]\narticleType: Number of classes: 140\nseason: Unique values: [0 2 3 1]\nseason: Number of classes: 4\ngender: Unique values: [2 4 0 1 3]\ngender: Number of classes: 5\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Convert labels to categorical format\n\ntrain_labels = [to_categorical(train_generator.labels[:, i]) for i in range(4)]\ntest_labels = [to_categorical(test_generator.labels[:, i]) for i in range(4)]\n\n\n# # Convert labels to categorical format\n# num_classes = [len(train_df[column].unique()) for column in ['baseColour', 'articleType', 'season', 'gender']]\n# num_classes[1] = 50  # Update the number of classes for \"articleType\" column\n\n# train_labels = [to_categorical(train_generator.labels[:, i], num_classes[i]) for i in range(4)]\n# test_labels = [to_categorical(test_generator.labels[:, i], num_classes[i]) for i in range(4)]","metadata":{"execution":{"iopub.status.busy":"2023-05-28T07:41:22.279858Z","iopub.execute_input":"2023-05-28T07:41:22.280356Z","iopub.status.idle":"2023-05-28T07:41:22.306464Z","shell.execute_reply.started":"2023-05-28T07:41:22.280316Z","shell.execute_reply":"2023-05-28T07:41:22.304967Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# You can use weights='Imagenet' or manually download mobilenet v2 h5 file and load it ","metadata":{}},{"cell_type":"code","source":"# Build the deep learning model\nbase_model = MobileNetV2(weights='/kaggle/input/mobilenetv2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5', include_top=False, input_shape=(224, 224, 3))\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n\n\n# Define output layers for each label\noutput_baseColour = Dense(num_classes[0], activation='softmax')(x)\noutput_articleType = Dense(num_classes[1], activation='softmax')(x)\noutput_season = Dense(num_classes[2], activation='softmax')(x)\noutput_gender = Dense(num_classes[3], activation='softmax')(x)\nprint(\"Color shape: \", output_baseColour.shape)\nprint(\"Article type shape: \", output_articleType.shape)\nprint(\"Season shape: \", output_season.shape)\nprint(\"Gender shape: \", output_gender.shape)\n# Create the model\nmodel = Model(inputs=base_model.input, outputs=[output_baseColour, output_articleType, output_season, output_gender])\n\n# Compile the model with appropriate loss functions\nlosses = ['categorical_crossentropy'] * 4  # Use categorical cross-entropy for each output\nmodel.compile(optimizer='adam', loss=losses, metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-28T07:45:46.410188Z","iopub.execute_input":"2023-05-28T07:45:46.410595Z","iopub.status.idle":"2023-05-28T07:45:48.501269Z","shell.execute_reply.started":"2023-05-28T07:45:46.410556Z","shell.execute_reply":"2023-05-28T07:45:48.499898Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Color shape:  (None, 46)\nArticle type shape:  (None, 140)\nSeason shape:  (None, 4)\nGender shape:  (None, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model\nmodel.fit(train_generator, validation_data=test_generator,epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\n\n# Path to the saved model file\nmodel_path = \"path_to_saved_model.h5\"  # Replace with the actual model path\n\n# Load the model\nmodel = load_model(model_path)\n\n# Path to the fashion product image you want to predict\nimage_path = \"path_to_image.jpg\"  # Replace with the actual image path\n\n# Load the image and preprocess it\nimg = image.load_img(image_path, target_size=image_size)\nimg_array = image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array /= 255.0  # Normalize the image\n\n# Make predictions\npredictions = model.predict(img_array)\n\n# Decode the predictions\ndecoded_predictions = []\nfor i in range(len(predictions)):\n    decoded_predictions.append(label_encoder[i].inverse_transform(np.argmax(predictions[i])))\n\n# Print the predicted labels\nprint(\"Predicted base colour:\", decoded_predictions[0])\nprint(\"Predicted article type:\", decoded_predictions[1])\nprint(\"Predicted season:\", decoded_predictions[2])\nprint(\"Predicted gender:\", decoded_predictions[3])\n","metadata":{},"execution_count":null,"outputs":[]}]}